"""Fill in a module description here"""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['get_lib_seq_context', 'get_sites_in_seq', 'score', 'identify_depleted_motifs_scanning_ends', 'filter_to_core_motifs',
           'get_fold_change_values_per_site', 'filter_sequences_without_core_motifs', 'get_sites_scores',
           'filter_to_core_flexible_motifs', 'plot_flexible_motif_analysis']

# %% ../nbs/00_core.ipynb 3
import pandas as pd
import seaborn as sns
from tqdm import tqdm
import re
import matplotlib.pyplot as plt
import numpy as np
from scipy.stats import pearsonr,spearmanr
import os
from collections import Counter, defaultdict
import re
from random import choice
from itertools import groupby, chain
from operator import itemgetter
import os
from .utils import revcomp, calculate_log2fc, allseqs, get_all_sites, flatten    
import ast

# %% ../nbs/00_core.ipynb 9
def get_lib_seq_context(seqs,left,right):
    """
    Generates a list of sequences by combining a left and right sequence with each sequence in the input list.
    
    Args:
        seqs (list): List of sequences to be combined.
        left (str): Left sequence to prepend.
        right (str): Right sequence to append.

    Returns:
        list: List of combined sequences.
    """
    left=left.upper()
    right=right.upper()
    lib=[left+r+right for r in seqs]
    return lib


# %% ../nbs/00_core.ipynb 12
def get_sites_in_seq(lib,pattern=(3,6,4),no_ori=True):
    '''Computes the list of unique sites matching the pattern present in each sequence of the library
    The pattern is a list of 3 number:
        1. The number of defined bases in the first part of the site
        2. The number of undefined bases in the middle
        3. The number of defined bases in the second part of the site
    '''
    #Checks all sequences are the same size
    if len(set([len(s) for s in lib]))!=1:
        return 'not all sequences in library are the same size'
    
    L=len(lib[0])
    
    if len(pattern)>L:
        return 'site specifications are longer than the sequence provided'
    
    
    set_list=[]
    for seq in lib:
        sites=re.findall("(?=([ATGC]{{{}}})([ATGC]{{{}}})([ATGC]{{{}}}))".format(pattern[0],pattern[1],pattern[2]),seq)
        if no_ori==True:
            rev=revcomp(seq)
            sites+=re.findall("(?=([ATGC]{{{}}})([ATGC]{{{}}})([ATGC]{{{}}}))".format(pattern[0],pattern[1],pattern[2]),rev)
        set_list.append(set([s1+'N'*pattern[1]+s3 for s1,s2,s3 in sites]))

    return set_list

# %% ../nbs/00_core.ipynb 14
def score(FCs, thr=-1):
    """
    Returns the fraction of sequences depleted below the thr value.
    Handles empty lists of FCs by returning 0.
    """
    if len(FCs)==0:  # Check if the list is empty
        return 0.0
    return sum([x < thr for x in FCs]) / len(FCs)

# %% ../nbs/00_core.ipynb 16
def identify_depleted_motifs_scanning_ends(log2fc_series, 
                                           scan_depth_k=6, 
                                           max_motif_length=6, 
                                           depletion_threshold=-1, 
                                           score_thr=0.85, 
                                           min_sequence_support=5):
    """
    Identifies DNA motifs associated with sequence depletion by scanning k positions
    from both the left and right ends of sequences, using a pandas Series of log2FC values.

    Args:
        log2fc_series (pd.Series): pandas Series with sequences (DNA strings) as index
                                   and log2FC values as data.
        scan_depth_k (int): The number of positions to scan from each end (0 to k inclusive).
        max_motif_length (int): The maximum length of the motif to consider.
        depletion_threshold (float): The log2FC threshold for considering a sequence depleted.
        min_sequence_support (int): The minimum number of sequences (strictly greater than this value)
                                    a motif must be found in to be included in the results.

    Returns:
        pd.DataFrame: A DataFrame with identified motifs, their length, actual 0-indexed position,
                      number of occurrences, average log2FC, and depletion score (fraction_depleted).
                      Sorted by primary depletion metrics.
    """
    if not isinstance(log2fc_series, pd.Series):
        print(f"Error: Input must be a pandas Series.")
        return pd.DataFrame(columns=['motif', 'length', 'position', 'num_sequences', 'avg_log2fc', 'fraction_depleted'])

    if log2fc_series.empty:
        print(f"Error: Input Series is empty.")
        return pd.DataFrame(columns=['motif', 'length', 'position', 'num_sequences', 'avg_log2fc', 'fraction_depleted'])

    current_log2fc_series = pd.to_numeric(log2fc_series.copy(), errors='coerce')
    series_name = current_log2fc_series.name if current_log2fc_series.name else "input Series"
    print(f"Analyzing motifs of length 1 to {max_motif_length}, scanning positions 0 to {scan_depth_k} from each end, for {series_name}.")
    print(f"Minimum sequence support for a motif: > {min_sequence_support} (i.e., {min_sequence_support +1} or more)")


    motif_stats_accumulator = {}

    # Iterate over (sequence_string, log2fc_value) pairs
    for seq_str, log2fc_val in current_log2fc_series.items(): 
        if pd.isna(log2fc_val) or not isinstance(seq_str, str):
            continue

        processed_positions_for_this_seq = set() 
        for motif_len in range(1, max_motif_length + 1):
            if len(seq_str) < motif_len:
                continue

            # Left scans
            for j_offset in range(scan_depth_k + 1):
                actual_pos_left = j_offset
                if actual_pos_left + motif_len <= len(seq_str):
                    if (actual_pos_left, motif_len) not in processed_positions_for_this_seq:
                        motif = seq_str[actual_pos_left : actual_pos_left + motif_len]
                        key = (motif, actual_pos_left, motif_len) 
                        if key not in motif_stats_accumulator:
                            motif_stats_accumulator[key] = []
                        motif_stats_accumulator[key].append(log2fc_val)
                        processed_positions_for_this_seq.add((actual_pos_left, motif_len))

            # Right scans
            for j_offset in range(scan_depth_k + 1):
                actual_pos_right = len(seq_str) - motif_len - j_offset
                if actual_pos_right >= 0 and actual_pos_right + motif_len <= len(seq_str):
                    if (actual_pos_right, motif_len) not in processed_positions_for_this_seq:
                        motif = seq_str[actual_pos_right : actual_pos_right + motif_len]
                        key = (motif, actual_pos_right, motif_len) 
                        if key not in motif_stats_accumulator:
                            motif_stats_accumulator[key] = []
                        motif_stats_accumulator[key].append(log2fc_val)
                        processed_positions_for_this_seq.add((actual_pos_right, motif_len))
    
    if not motif_stats_accumulator:
        print("No motifs found or no valid data to process based on scan parameters.")
        return pd.DataFrame(columns=['motif', 'length', 'position', 'num_sequences', 'avg_log2fc', 'fraction_depleted'])

    # Use a list comprehension for conciseness
    results = [
        {
            'motif': key[0],             # motif_str
            'length': key[2],            # motif_len
            'position': key[1],          # actual_pos
            'num_sequences': len(fc_values_list), 
            'avg_log2fc': np.mean(fc_values_list),
            'fraction_depleted': score(fc_values_list, depletion_threshold)
        }
        for key, fc_values_list in motif_stats_accumulator.items()
        if len(fc_values_list) > min_sequence_support # Apply min_sequence_support filter
    ]
    
    if not results:
        print(f"No motifs found meeting the minimum sequence support of > {min_sequence_support}.")
        return pd.DataFrame(columns=['motif', 'length', 'position', 'num_sequences', 'avg_log2fc', 'fraction_depleted'])

    results_df = pd.DataFrame(results)
    results_df = results_df.sort_values(
        by=['fraction_depleted', 'avg_log2fc', 'num_sequences'],
        ascending=[False, True, False]
    )
    results_df = results_df.loc[results_df['fraction_depleted'] > score_thr]
    return results_df

# %% ../nbs/00_core.ipynb 18
def filter_to_core_motifs(depleted_motifs_df, 
                          score_improvement_margin=0.05):
    """
    Filters a DataFrame of depleted motifs to identify underlying "core" motifs.
    A longer motif is kept only if it's significantly better than a shorter core motif it contains.

    Args:
        depleted_motifs_df (pd.DataFrame): DataFrame from identify_depleted_motifs_scanning_ends.
        score_improvement_margin (float): A longer motif's 'fraction_depleted' must be
                                          greater than the core motif's score by this margin.
        fc_improvement_margin (float): A longer motif's 'avg_log2fc' must be lower
                                       than the core motif's avg_log2fc by this margin.

    Returns:
        pd.DataFrame: A filtered DataFrame containing potentially core motifs.
    """
    if depleted_motifs_df.empty:
        return pd.DataFrame(columns=depleted_motifs_df.columns)

    sorted_df = depleted_motifs_df.sort_values(
        by=['length','fraction_depleted'],
        ascending=[True, False]
    ).reset_index(drop=True)

    core_motifs_list = []
    
    for idx, candidate_row in sorted_df.iterrows():
        candidate_motif = candidate_row['motif']
        candidate_pos = candidate_row['position']
        candidate_len = candidate_row['length']
        candidate_score = candidate_row['fraction_depleted']
        
        is_subsumed = False
        for core_dict in core_motifs_list: 
            core_motif = core_dict['motif']
            core_pos = core_dict['position']
            core_len = core_dict['length']
            core_score = core_dict['fraction_depleted']
            
            if core_len < candidate_len and core_motif in candidate_motif:    
                relative_start = candidate_motif.find(core_motif)
                if candidate_pos + relative_start == core_pos:
                    significantly_better_score = candidate_score >= core_score - score_improvement_margin
                        
                    if significantly_better_score:
                        is_subsumed = True
                        break 
        
        if not is_subsumed:
            core_motifs_list.append(candidate_row.to_dict())
            
    if not core_motifs_list:
         return pd.DataFrame(columns=depleted_motifs_df.columns)
    return pd.DataFrame(core_motifs_list)



# %% ../nbs/00_core.ipynb 20
def get_fold_change_values_per_site(site_sets_list, fold_changes_list):
    """
    Computes a dictionary mapping each unique site to a list of its associated
    log2 Fold Change (FC) values.

    Args:
        site_sets_list (list): A list of sets, where each set contains the sequence motifs found in a member of the library.
        fold_changes_list (list): A list of log2FC values, corresponding to each
                                  sequence in the library.

    Returns:
        dict: A dictionary where keys are sequence motifs and values are numpy arrays
              containing the log2FC values associated with that site.
    """

    # Step 1: Create a flat list of (site, FC_value) pairs
    # Each site within a set is associated with that set's FC value.
    site_fc_pairs_nested = [
     [(site, fc_value) for site in site_set]
     for site_set, fc_value in zip(site_sets_list, fold_changes_list)
     ]
    site_fc_pairs = list(chain.from_iterable(site_fc_pairs_nested)) # Standard way to flatten

    # Step 2: Sort the pairs by site to prepare for grouping
    # Sorting is essential for groupby to work correctly.
    site_fc_pairs.sort(key=itemgetter(0)) # Sorts by the first element (site)

    # Step 3: Group by site and collect FC values
    site_to_fcs_map = {}
    for site, group in groupby(site_fc_pairs, key=itemgetter(0)):
        # group is an iterator of (site, fc_value) tuples for the current site
        # Extract the FC value (the second element) from each pair in the group
        fcs_for_site = np.array([fc_value for current_site, fc_value in group])
        site_to_fcs_map[site] = fcs_for_site

    return site_to_fcs_map


# %% ../nbs/00_core.ipynb 22
def filter_sequences_without_core_motifs(log2fc_series, core_motifs_df):
    """
    Filters an original log2fc Series to remove sequences that contain 
    any of the specified core motifs.

    Args:
        log2fc_series (pd.Series): Series with sequences as its index and log2FC values.
        core_motifs_df (pd.DataFrame): DataFrame of core motifs, must include
                                       'motif', 'position', and 'length' columns.

    Returns:
        pd.Series: A new Series containing only sequences (and their log2FC values)
                   from log2fc_series that do not carry any of the core motifs.
    """
    if not isinstance(log2fc_series, pd.Series) or log2fc_series.empty:
        # print("Info: log2fc_series is empty or not a Series. Returning a copy.")
        return log2fc_series.copy() 
    
    expected_core_motif_cols = ['motif', 'position', 'length']
    if not isinstance(core_motifs_df, pd.DataFrame) or core_motifs_df.empty or \
       not all(col in core_motifs_df.columns for col in expected_core_motif_cols):
        print("Info: core_motifs_df is empty or invalid for filtering. Returning original log2fc_series.")
        return log2fc_series.copy()

    # Create a boolean mask, True for sequences to keep
    sequences_to_keep_mask = pd.Series(True, index=log2fc_series.index)

    # Iterate through each unique sequence string in the original Series' index
    # Using .loc for assignment to the mask handles duplicate indices in the original Series correctly
    for seq_str_to_check in log2fc_series.index.unique(): 
        if not isinstance(seq_str_to_check, str): 
            continue # Skip if index label is not a string
        
        # Check this sequence against all core motifs
        for _, motif_row in core_motifs_df.iterrows():
            motif_str = motif_row['motif']
            try:
                position = int(motif_row['position'])
                motif_len = int(motif_row['length'])
            except (ValueError, TypeError):
                # print(f"Warning: Invalid position/length for motif {motif_str} in core_motifs_df. Skipping this motif.")
                continue 

            if not isinstance(motif_str, str) or not motif_str: 
                continue

            if len(seq_str_to_check) >= position + motif_len:
                if seq_str_to_check[position : position + motif_len] == motif_str:
                    # If a motif is found, mark all occurrences of this sequence string for removal
                    sequences_to_keep_mask.loc[log2fc_series.index == seq_str_to_check] = False 
                    break # Move to the next unique sequence_str_to_check

    return log2fc_series[sequences_to_keep_mask]

# %% ../nbs/00_core.ipynb 24
def get_sites_scores(site_FCs, pattern, log2FC_thr=-1):
    """ 
    Scores sites based on depletion and occurrence.
    Returns a pandas DataFrame with 'site', 'fraction_depleted', 'num_sequences', 'avg_log2fc'.
    """
    site_scores_list = []
    
    for site_key, fc_values in site_FCs.items():
        if not isinstance(fc_values, (list, np.ndarray)) or len(fc_values) == 0:
            continue # Skip if fc_values is not a list/array or is empty
            
        current_score = score(fc_values, log2FC_thr)
        num_occurrences = len(fc_values)
        avg_fc = np.mean(fc_values) if num_occurrences > 0 else np.nan
        
        site_scores_list.append({
            'motif': site_key,
            'fraction_depleted': current_score,
            'num_sequences': num_occurrences,
            'avg_log2fc': avg_fc
        })
            
    if not site_scores_list:
        return pd.DataFrame(columns=['motif', 'fraction_depleted', 'num_sequences', 'avg_log2fc'])
    return pd.DataFrame(site_scores_list)

# %% ../nbs/00_core.ipynb 26
def filter_to_core_flexible_motifs(flexible_motifs_df, score_margin=0.05):
    """
    Filters a DataFrame of flexible (position-independent) motifs to identify underlying "core" motifs.
    A longer/more complex motif is removed if its score is not significantly better than a simpler
    core motif pattern it contains.

    Args:
        flexible_motifs_df (pd.DataFrame): DataFrame with 'site', 'pattern' (string like '(3,4,4)'),
                                           'fraction_depleted', 'num_sequences', 'avg_log2fc'.
        score_margin (float): A more complex motif is subsumed if its 'fraction_depleted'
                              is not better than (core_score - score_margin).
                              Effectively, if candidate_score >= core_score - score_margin, it's subsumed.

    Returns:
        pd.DataFrame: A filtered DataFrame containing potentially core flexible motifs.
    """
    if not isinstance(flexible_motifs_df, pd.DataFrame) or flexible_motifs_df.empty:
        return pd.DataFrame(columns=flexible_motifs_df.columns)

    # Ensure required columns exist
    required_cols = ['motif', 'pattern', 'fraction_depleted', 'avg_log2fc', 'num_sequences']
    if not all(col in flexible_motifs_df.columns for col in required_cols):
        print("Warning (filter_to_core_flexible_motifs): DataFrame missing required columns. Returning original.")
        return flexible_motifs_df.copy()

    # 1. Parse 'pattern' string and add helper columns
    df = flexible_motifs_df.copy()
    try:
        df['pattern_tuple'] = df['pattern'].apply(ast.literal_eval)
        df['p0'] = df['pattern_tuple'].apply(lambda x: x[0])
        df['p1_Ns'] = df['pattern_tuple'].apply(lambda x: x[1])
        df['p2'] = df['pattern_tuple'].apply(lambda x: x[2])
        df['defined_len'] = df['p0'] + df['p2']
    except Exception as e:
        print(f"Error parsing 'pattern' column in filter_to_core_flexible_motifs: {e}. Returning original DataFrame.")


    # 2. Sort by simplicity then score
    sorted_df = df.sort_values(
        by=['p1_Ns', 'defined_len', 'fraction_depleted', 'avg_log2fc', 'num_sequences'],
        ascending=[True, True, False, True, False]
    ).reset_index(drop=True)

    core_flex_list = []
    for _, candidate_row in sorted_df.iterrows():
        cand_site = candidate_row['motif']
        cand_p0, cand_p1_Ns, cand_p2 = candidate_row['p0'], candidate_row['p1_Ns'], candidate_row['p2']
        cand_score = candidate_row['fraction_depleted']
        # cand_avgfc = candidate_row['avg_log2fc'] # Not used in this subsumption logic for now

        is_subsumed = False
        for core_dict in core_flex_list: # Compare with already accepted core motifs
            core_site = core_dict['motif']
            core_p0, core_p1_Ns, core_p2 = core_dict['p0'], core_dict['p1_Ns'], core_dict['p2']
            core_score = core_dict['fraction_depleted']
            # core_avgfc = core_dict['avg_log2fc']

            # Simplicity check: core must be simpler than candidate
            is_simpler = (core_p0 + core_p2 <= cand_p0 + cand_p2) 
            if is_simpler:
                # Containment check: Does candidate_site contain the core_site pattern?
                # Convert core_site to a regex where Ns are wildcards
                core_site_part1 = core_site[0:core_p0]
                core_site_part2 = core_site[core_p0 + core_p1_Ns : core_p0 + core_p1_Ns + core_p2]
                
                core_regex_parts = []
                if core_p0 > 0: core_regex_parts.append(re.escape(core_site_part1))
                if core_p1_Ns > 0: core_regex_parts.append(f"[ATGCN]{{{core_p1_Ns}}}") # Match any base for Ns
                if core_p2 > 0: core_regex_parts.append(re.escape(core_site_part2))
                core_regex = "".join(core_regex_parts)
                if core_regex: # Ensure regex is not empty
                    try:
                        if re.search(core_regex, cand_site):
                            is_subsumed = True
                            break 
                        if re.search(core_regex, revcomp(cand_site)):
                            is_subsumed = True
                            break

                    except re.error:
                        # print(f"Regex error for core pattern: {core_regex}")
                        continue # Skip this core if its regex is bad
                
        
        if not is_subsumed:
            # Add original columns, not the temporary ones, to the list
            core_flex_list.append(candidate_row.to_dict())

    if not core_flex_list:
        return pd.DataFrame(columns=flexible_motifs_df.columns)
    
    return pd.DataFrame(core_flex_list)[flexible_motifs_df.columns]

# %% ../nbs/00_core.ipynb 34
def plot_flexible_motif_analysis(counts_df, sample_col, ref_col, flexible_motifs_df, 
                                   left_context_str, right_context_str, 
                                   title_main="Flexible Motif Analysis", pseudocount=1):
    """
    Generates two subplots for FLEXIBLE (position-independent) motifs, considering sequence context.
    Uses get_flexible_motif_presence_in_library to simplify highlighting.
    """
    motif_presence_df = get_flexible_motif_presence_in_library(
            counts_df.index.tolist(), left_context_str, right_context_str, flexible_motifs_df
        )

    # --- Minimal defaulting for flexible_motifs_df to prevent immediate errors ---
    # If it's not a valid DataFrame with 'motif' and 'pattern', treat as no motifs.
    if not (isinstance(flexible_motifs_df, pd.DataFrame) and \
            'motif' in flexible_motifs_df.columns and \
            'pattern' in flexible_motifs_df.columns): # pattern needed for dummy
        flexible_motifs_df = pd.DataFrame(columns=['motif', 'pattern'])
    # Note: Other inputs (counts_df, sample_col, etc.) are now assumed to be valid by the caller.

    # --- Data Preparation ---
    plot_df = counts_df.copy()
    plot_df['sample_numeric'] = pd.to_numeric(plot_df[sample_col], errors='coerce')
    plot_df['ref_numeric'] = pd.to_numeric(plot_df[ref_col], errors='coerce')

    total_sample = plot_df['sample_numeric'].sum()
    total_ref = plot_df['ref_numeric'].sum()

    if total_sample == 0 or total_ref == 0:
        plot_df['y_plot_values'] = plot_df['sample_numeric'].fillna(0) + pseudocount
        plot_df['x_plot_values'] = plot_df['ref_numeric'].fillna(0) + pseudocount
        norm_label_suffix = f"(Counts + {pseudocount}, log scale) - Norm. Failed"
    else:
        plot_df['y_plot_values'] = (plot_df['sample_numeric'] / total_sample * 1e6).fillna(0) + pseudocount
        plot_df['x_plot_values'] = (plot_df['ref_numeric'] / total_ref * 1e6).fillna(0) + pseudocount
        norm_label_suffix = f"(CPM + {pseudocount}, log scale)"

    # --- Plotting Setup ---
    fig, axes = plt.subplots(1, 1, figsize=(10, 8))
    fig.suptitle(title_main, fontsize=16)
    ax_scatter_flex = axes
    ax_scatter_flex.scatter(plot_df['x_plot_values'], plot_df['y_plot_values'], color='grey', alpha=0.5, s=10, label='All Sequences')
    for _ , motif in flexible_motifs_df.iterrows():
        df_flt=plot_df.loc[motif_presence_df[motif['motif']].values]
        ax_scatter_flex.scatter(df_flt['x_plot_values'], df_flt['y_plot_values'], alpha=0.5, s=10, label=motif['motif'])
    ax_scatter_flex.loglog()
    ax_scatter_flex.legend()
    plt.show()

