{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils\n",
    "\n",
    "> useful basic functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr,spearmanr\n",
    "import os\n",
    "from collections import Counter, defaultdict\n",
    "import re\n",
    "from random import choice\n",
    "from itertools import groupby, chain\n",
    "from operator import itemgetter\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from randseq.example_data import get_example_data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def calculate_log2fc(df, reference_column='MFDpir', count_threshold=20, pseudocount=1):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame, normalizes columns by sum, calculates log2 fold change\n",
    "    relative to a reference column, and drops the reference column.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Input DataFrame (rows=features, columns=samples).\n",
    "        reference_column (str): Name of the reference sample column.\n",
    "        count_threshold (int): Minimum count in reference column to keep a feature.\n",
    "        pseudocount (float): Value added to normalized counts before log2FC.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with log2 fold change values. None if reference\n",
    "                      column is missing. Empty DataFrame if all rows are filtered out.\n",
    "    \"\"\"\n",
    "    if reference_column not in df.columns:\n",
    "        print(f\"Error: Reference column '{reference_column}' not found in DataFrame.\")\n",
    "        return None\n",
    "\n",
    "    # 1. Filter rows\n",
    "    df_filtered = df[df[reference_column] > count_threshold].copy()\n",
    "    if df_filtered.empty:\n",
    "        print(\"DataFrame is empty after filtering.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # 2. Add pseudocount\n",
    "    # The pseudocount is added here, before normalization.\n",
    "    df_with_pseudocount = df_filtered + pseudocount\n",
    "\n",
    "    # 3. Normalize each column by its sum\n",
    "    # Normalization is now performed on the data that includes the pseudocount.\n",
    "    # df.sum(axis=0) calculates sum for each column.\n",
    "    # .div performs element-wise division, axis=1 aligns column_sums with columns.\n",
    "    column_sums = df_with_pseudocount.sum(axis=0)\n",
    "    \n",
    "    # Handle cases where column_sums might be zero (e.g., if all values were -pseudocount after filtering, though unlikely with positive counts)\n",
    "    # If a column sum is 0 after adding pseudocount, it implies an issue or very specific data.\n",
    "    # Division by zero will result in NaN or inf.\n",
    "    df_processed = df_with_pseudocount.div(column_sums, axis=1)\n",
    "\n",
    "    # Check if reference column still exists (it should)\n",
    "    if reference_column not in df_processed.columns:\n",
    "        # This check is crucial as operations might alter columns if not handled carefully.\n",
    "        print(f\"Error: Reference column '{reference_column}' lost during processing.\")\n",
    "        return None\n",
    "        \n",
    "    reference_values = df_processed[reference_column]\n",
    "\n",
    "    # 4. Calculate log2FC\n",
    "    # .div performs element-wise division, axis=0 aligns reference_values (a Series) with rows of df_processed.\n",
    "    log2fc_df = np.log2(df_processed.div(reference_values, axis=0))\n",
    "    \n",
    "    # Columns are already named correctly from df_processed.\n",
    "\n",
    "    # 5. Drop the reference column's own log2FC (which will be ~zeros)\n",
    "    if reference_column in log2fc_df.columns:\n",
    "        log2fc_df = log2fc_df.drop(columns=[reference_column])\n",
    "    else:\n",
    "        print(f\"Warning: Reference column '{reference_column}' not found in log2fc_df for dropping.\")\n",
    "        \n",
    "    return log2fc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__init__.py', 'countsTable.csv', '__pycache__']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| hide\n",
    "data_path=get_example_data_dir()\n",
    "os.listdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "K12_T0       -2.844874\n",
       "HS_T0        -3.320280\n",
       "E1114_T0     -4.544421\n",
       "E1167_T0     -3.645600\n",
       "H120_T0      -3.572726\n",
       "TA054_T0     -3.319211\n",
       "TA447_T0     -3.566876\n",
       "E101_T0      -8.108167\n",
       "41-1Ti9_T0   -4.255918\n",
       "TA280_T0     -4.800802\n",
       "M114_T0      -4.143357\n",
       "TA249_T0     -4.973009\n",
       "ROAR8_T0     -4.621302\n",
       "JJ1886_T0    -9.188692\n",
       "CFT073_T0    -3.868714\n",
       "APECO1_T0    -6.525634\n",
       "UTI89_T0     -8.571068\n",
       "S88_T0       -8.601767\n",
       "MG1655_T0    -4.777041\n",
       "dtype: float64"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_file=\"countsTable.csv\"\n",
    "file_path=os.path.join(data_path,counts_file)\n",
    "counts=pd.read_csv(file_path, index_col=0)\n",
    "counts = counts[[col for col in counts.columns if (\"_T0\" in col) or (\"MFDpir\" in col)]]\n",
    "\n",
    "log2fc_df = calculate_log2fc(counts, reference_column='MFDpir', count_threshold=20, pseudocount=1)\n",
    "log2fc_df.min(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def revcomp(seq:str):\n",
    "    '''Computes the reverse complement of a sequence'''\n",
    "    trns=str.maketrans(\"ATGCN\",\"TACGN\")\n",
    "    return seq.upper().translate(trns)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert revcomp(\"ATGC\")==\"GCAT\"\n",
    "assert revcomp(\"ATGCN\")==\"NGCAT\"\n",
    "assert revcomp(\"atgNN\")==\"NNCAT\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "bases=list(\"ATGC\")\n",
    "def allseqs(n,seqs=[\"\"]):\n",
    "    '''Recursive function that generates all possible sequences of length n\n",
    "    seqs is a list of sequences to which we will add bases\n",
    "    '''\n",
    "    seqs=[s+b for s in seqs for b in bases]\n",
    "    if len(seqs[0])<n:\n",
    "        return allseqs(n,seqs)\n",
    "    else:\n",
    "        return seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AA,AT,AG,AC,TA,TT,TG,TC,GA,GT,GG,GC,CA,CT,CG,CC'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\",\".join(allseqs(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert flatten([[1,2],[3,4],[5,6]])==[1, 2, 3, 4, 5, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_all_sites(pattern):\n",
    "    #generates a list of all sites that match the pattern\n",
    "    return [s[:pattern[0]]+\"N\"*pattern[1]+s[pattern[0]:] for s in allseqs(pattern[0]+pattern[2])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AAANNNNNNAAAA',\n",
       " 'AAANNNNNNAAAT',\n",
       " 'AAANNNNNNAAAG',\n",
       " 'AAANNNNNNAAAC',\n",
       " 'AAANNNNNNAATA']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_all_sites((3,6,4))[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
